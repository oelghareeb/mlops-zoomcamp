{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79884d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime \n",
    "from datetime import datetime \n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b6f339",
   "metadata": {},
   "source": [
    "### Functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d317dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(link):\n",
    "    df = pd.read_parquet(link)\n",
    "    \n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    \n",
    "    df = df[(df['duration'] >= 1) & (df['duration'] <= 60)]\n",
    "    \n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e36744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet')\n",
    "df_validate = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9dacf6",
   "metadata": {},
   "source": [
    "# Q1. Downloading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a0a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f13924",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2024-01-01 00:57:55</td>\n",
       "      <td>2024-01-01 01:17:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:03:00</td>\n",
       "      <td>2024-01-01 00:09:36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>140</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:17:06</td>\n",
       "      <td>2024-01-01 00:35:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:36:38</td>\n",
       "      <td>2024-01-01 00:44:56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-01 00:46:51</td>\n",
       "      <td>2024-01-01 00:52:57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43              1.0   \n",
       "1         1  2024-01-01 00:03:00   2024-01-01 00:09:36              1.0   \n",
       "2         1  2024-01-01 00:17:06   2024-01-01 00:35:01              1.0   \n",
       "3         1  2024-01-01 00:36:38   2024-01-01 00:44:56              1.0   \n",
       "4         1  2024-01-01 00:46:51   2024-01-01 00:52:57              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           1.72         1.0                  N           186            79   \n",
       "1           1.80         1.0                  N           140           236   \n",
       "2           4.70         1.0                  N           236            79   \n",
       "3           1.40         1.0                  N            79           211   \n",
       "4           0.80         1.0                  N           211           148   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2         17.7    1.0      0.5        0.00           0.0   \n",
       "1             1         10.0    3.5      0.5        3.75           0.0   \n",
       "2             1         23.3    3.5      0.5        3.00           0.0   \n",
       "3             1         10.0    3.5      0.5        2.00           0.0   \n",
       "4             1          7.9    3.5      0.5        3.20           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
       "0                    1.0         22.70                   2.5          0.0  \n",
       "1                    1.0         18.75                   2.5          0.0  \n",
       "2                    1.0         31.30                   2.5          0.0  \n",
       "3                    1.0         17.00                   2.5          0.0  \n",
       "4                    1.0         16.10                   2.5          0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3c3fc",
   "metadata": {},
   "source": [
    "### Read the data for January. How many columns are there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9de760c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns = 19\n"
     ]
    }
   ],
   "source": [
    "print(f'The number of columns = {_.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9436379",
   "metadata": {},
   "source": [
    "# Q2. Computing duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "694879d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545837ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.851053592192876"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_['duration'] = (_['tpep_dropoff_datetime'] - _['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "_['duration'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97eae702",
   "metadata": {},
   "source": [
    "# Q3. Dropping outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86caa1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of records left after dropping outliers (rounded): 98 %\n"
     ]
    }
   ],
   "source": [
    "# Calculate the fraction of records left after removing outliers\n",
    "fraction_left = len(df_train) / len(_)\n",
    "\n",
    "# Percentage \n",
    "print(f\"Fraction of records left after dropping outliers (rounded): {round(fraction_left * 100)} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460eb612",
   "metadata": {},
   "source": [
    "# Q4. One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207c162b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2898906, 2938060)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ac3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['PU-DO'] = df_train['PULocationID'] + '-' + df_train['DOLocationID']\n",
    "# df_validate['PU-DO'] = df_validate['PULocationID'] + '-' + df_validate['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7ee8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical = ['PU-DO']\n",
    "# numerical = ['trip_distance']\n",
    "\n",
    "# dv = DictVectorizer(sparse = True)\n",
    "\n",
    "# train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "# X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# validate_dicts = df_validate[categorical + numerical].to_dict(orient='records')\n",
    "# X_validate = dv.fit_transform(validate_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1acac408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1600b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PULocationID', 'DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8540fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to a list of dictionaries\n",
    "train_dict = df_train[categorical].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca33b754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer(sparse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e14955c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2898906, 518)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.fit(train_dict)\n",
    "X_train=dv.transform(train_dict)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f18fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the feature matrix: 518\n"
     ]
    }
   ],
   "source": [
    "# Get the dimensionality of the feature matrix\n",
    "num_columns = X_train.shape[1]\n",
    "\n",
    "print(\"Dimensionality of the feature matrix:\", num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda32d41",
   "metadata": {},
   "source": [
    "# Q5. Training a model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f2b10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_validate = df_validate[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b1b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train: 7.946173359562653\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)  \n",
    "\n",
    "# Predict on the training data\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "# Calculate the RMSE on the training data\n",
    "rmse_train = mean_squared_error(y_train, predictions_train, squared=False)\n",
    "\n",
    "print(\"RMSE on train:\", rmse_train)\n",
    "\n",
    "# Save the trained model using pickle\n",
    "with open('linear_regression_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181493f9",
   "metadata": {},
   "source": [
    "# Q6. Evaluating the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a21e7664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the feature matrix: 514\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to a list of dictionaries\n",
    "validate_dict = df_validate[categorical].to_dict(orient='records')\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dv = DictVectorizer(sparse = True)\n",
    "\n",
    "dv.fit(validate_dict)\n",
    "X_validate=dv.transform(validate_dict)\n",
    "X_validate.shape\n",
    "\n",
    "# Get the dimensionality of the feature matrix\n",
    "num_columns = X_validate.shape[1]\n",
    "\n",
    "print(\"Dimensionality of the feature matrix:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27a35851",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 514 features, but LinearRegression is expecting 518 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     loaded_model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Predict on the validation data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m predictions_validation \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_validate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate the RMSE on the validation data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m rmse_validation \u001b[38;5;241m=\u001b[39m mean_squared_error(y_validate, predictions_validation, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:362\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:345\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    343\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcoo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 514 features, but LinearRegression is expecting 518 features as input."
     ]
    }
   ],
   "source": [
    "# Load the saved model using pickle\n",
    "with open('linear_regression_model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "# Predict on the validation data\n",
    "predictions_validation = loaded_model.predict(X_validate)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_validation = mean_squared_error(y_validate, predictions_validation, squared=False)\n",
    "\n",
    "print(\"RMSE on validation:\", rmse_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c717c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
